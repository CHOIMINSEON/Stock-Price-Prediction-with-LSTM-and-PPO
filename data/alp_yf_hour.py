import os
import tempfile

import alpaca_trade_api as tradeapi
from alpaca_trade_api.rest import TimeFrame
import yfinance as yf
import pandas as pd
from dotenv import load_dotenv

# ==========================================
# [1] ì„¤ì • ì˜ì—­
# ==========================================
load_dotenv()

API_KEY = os.getenv("ALPACA_API_KEY")
SECRET_KEY = os.getenv("ALPACA_SECRET_KEY")

if not API_KEY or not SECRET_KEY:
    raise ValueError("âŒ .env íŒŒì¼ì—ì„œ ALPACA_API_KEY ë˜ëŠ” ALPACA_SECRET_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ê¸°ê°„ ë° ê¸°ë³¸ ì„¤ì •
START_DATE = "2016-01-01"
END_DATE = "2025-12-01"
INTERVAL = "1h"
OUTPUT_TIMEZONE = "America/New_York"  # ëª¨ë“  ì‹œê³„ì—´ì„ ë‰´ìš• ì‹œê°„ìœ¼ë¡œ í†µì¼

SAVE_DIR = "E:/b/pj2/data"
TARGET_TICKERS = ['AAPL', 'AMZN', 'GOOGL', 'NVDA', 'AMD', 'META', 'PLTR', 'TSLA']

# ê±°ì‹œì§€í‘œëŠ” yfinance ì¼ë´‰ìœ¼ë¡œë§Œ ìˆ˜ì§‘
MACRO_TICKERS = {
    'VIX': '^VIX',
    'TNX': '^TNX',
    'DXY': 'DX-Y.NYB'
}

# ì‹œì¥ ETFëŠ” Alpacaì—ì„œ ì‹œì„¸ë¥¼ ë°›ì•„ ê° íŒŒì¼ ì—´ë¡œë§Œ ì¶”ê°€
MARKET_ETFS = ['QQQ', 'XLK']

os.makedirs(SAVE_DIR, exist_ok=True)


# ==========================================
# [2] ë³´ì¡° í•¨ìˆ˜ (RSI, MACD, ATR, VWAP)
# ==========================================

def calculate_rsi(series: pd.Series, period: int = 14) -> pd.Series:
    delta = series.diff(1)
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    avg_gain = gain.rolling(window=period).mean()
    avg_loss = loss.rolling(window=period).mean()
    rs = avg_gain / avg_loss
    rsi = 100 - (100 / (1 + rs))
    return rsi


def calculate_macd(series: pd.Series, fast: int = 12, slow: int = 26, signal: int = 9):
    exp1 = series.ewm(span=fast, adjust=False).mean()
    exp2 = series.ewm(span=slow, adjust=False).mean()
    macd = exp1 - exp2
    signal_line = macd.ewm(span=signal, adjust=False).mean()
    macd_hist = macd - signal_line
    return macd, signal_line, macd_hist


def calculate_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:
    """Average True Range (ë³€ë™ì„± ì§€í‘œ)"""
    high = df['High']
    low = df['Low']
    close = df['Close']
    prev_close = close.shift(1)

    tr1 = high - low
    tr2 = (high - prev_close).abs()
    tr3 = (low - prev_close).abs()

    true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
    atr = true_range.rolling(window=period).mean()
    return atr


def calculate_vwap(df: pd.DataFrame) -> pd.Series:
    """VWAP: ê±°ë˜ëŸ‰ ê°€ì¤‘ í‰ê·  ê°€ê²© (ì„¸ì…˜ ì „ì²´ ê¸°ì¤€ ëˆ„ì )"""
    typical_price = (df['High'] + df['Low'] + df['Close']) / 3.0
    cum_vp = (typical_price * df['Volume']).cumsum()
    cum_vol = df['Volume'].cumsum()
    vwap = cum_vp / cum_vol
    return vwap


# ==========================================
# [3] ê±°ì‹œì§€í‘œ(yfinance, ì¼ë´‰) ìˆ˜ì§‘
# ==========================================

def fetch_macro_series():
    print(f"â° ì¼ë³„ ê±°ì‹œ ì‹œì¥ ì§€í‘œ ìˆ˜ì§‘ ì¤‘... ({START_DATE} ~ {END_DATE})")
    macro_series = {}
    available_macro_cols = []

    for name, ticker in MACRO_TICKERS.items():
        try:
            # ê±°ì‹œì§€í‘œëŠ” ëª¨ë‘ ì¼ë´‰(1d)ìœ¼ë¡œ ìˆ˜ì§‘ í›„, ì´í›„ ì‹œê°„ ì¸ë±ìŠ¤ì— ì±„ì›Œì„œ ì‚¬ìš©
            df = yf.download(
                ticker,
                start=START_DATE,
                end=END_DATE,
                interval='1d',
                progress=False,
                auto_adjust=False,
            )
            if df.empty:
                print(f"âš ï¸ {name} ìˆ˜ì§‘ ì‹¤íŒ¨: ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
                continue

            if isinstance(df.columns, pd.MultiIndex):
                df.columns = df.columns.get_level_values(0)

            col_to_use = 'Adj Close' if 'Adj Close' in df.columns else 'Close'
            series = df[col_to_use].copy()

            if series.dropna().empty:
                print(f"âš ï¸ {name} ìˆ˜ì§‘ ì‹¤íŒ¨: ìœ íš¨í•œ ì¢…ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            index = pd.to_datetime(series.index)
            if getattr(index, "tz", None) is None:
                index = index.tz_localize('UTC')
            else:
                index = index.tz_convert('UTC')
            index = index.tz_convert(OUTPUT_TIMEZONE)
            series.index = index.tz_localize(None)
            series.sort_index(inplace=True)

            macro_series[name] = series
            available_macro_cols.append(name)
        except Exception as e:
            print(f"âš ï¸ {name} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

    if available_macro_cols:
        joined = ", ".join(available_macro_cols)
        print(f"âœ… ìˆ˜ì§‘ëœ ê±°ì‹œ ì§€í‘œ: {joined}")
    else:
        print("âš ï¸ ê±°ì‹œ ì§€í‘œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return macro_series, available_macro_cols


# ==========================================
# [4] ETF (QQQ, XLK) ì‹œì„¸ ìˆ˜ì§‘ (Alpaca)
# ==========================================

def fetch_market_etfs(api: tradeapi.REST):
    etf_series = {}
    for symbol in MARKET_ETFS:
        try:
            bars = api.get_bars(
                symbol=symbol,
                timeframe=TimeFrame.Hour,
                start=START_DATE,
                end=END_DATE,
                adjustment='raw'
            ).df

            if bars.empty:
                print(f"âš ï¸ {symbol} ë°ì´í„° ì—†ìŒ (Alpaca)")
                continue

            idx = pd.to_datetime(bars.index)
            if getattr(idx, "tz", None) is None:
                idx = idx.tz_localize('UTC')
            else:
                idx = idx.tz_convert('UTC')
            idx = idx.tz_convert(OUTPUT_TIMEZONE)
            bars.index = idx.tz_localize(None)

            etf_series[symbol] = bars['close'].sort_index().copy()
            print(f"âœ… {symbol} ì‹œì„¸ ìˆ˜ì§‘ ì™„ë£Œ (Alpaca)")
        except Exception as e:
            print(f"âš ï¸ {symbol} ìˆ˜ì§‘ ì‹¤íŒ¨ (Alpaca): {e}")
    return etf_series


# ==========================================
# [5] Alpaca ì‹œì„¸ + ê±°ì‹œ/ê¸°ìˆ /ETF ì§€í‘œ ê²°í•©
# ==========================================

def build_alpaca_yf_hourly_dataset():
    print(f"ğŸš€ Alpaca ì‹œì„¸ + yfinance ê±°ì‹œ + ê¸°ìˆ ì§€í‘œ + ETF(QQQ, XLK) ê²°í•© ë°ì´í„° ìƒì„± ({START_DATE} ~ {END_DATE}, {INTERVAL})")

    api = tradeapi.REST(
        key_id=API_KEY,
        secret_key=SECRET_KEY,
        base_url='https://paper-api.alpaca.markets',
        api_version='v2'
    )

    macro_series, available_macro_cols = fetch_macro_series()
    etf_series = fetch_market_etfs(api)

    print("\nğŸš€ ê°œë³„ ì¢…ëª© ì‹œê°„ë³„ ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘...")

    for ticker in TARGET_TICKERS:
        print(f"[{ticker}] ì²˜ë¦¬ ì¤‘...", end=" ")
        try:
            bars = api.get_bars(
                symbol=ticker,
                timeframe=TimeFrame.Hour,
                start=START_DATE,
                end=END_DATE,
                adjustment='raw'
            ).df

            if bars.empty:
                print("âŒ ë°ì´í„° ì—†ìŒ")
                continue

            # ì¸ë±ìŠ¤(ì‹œê°„) ì²˜ë¦¬ ë° ë‰´ìš• ì‹œê°„ìœ¼ë¡œ ë³€í™˜
            index = pd.to_datetime(bars.index)
            if getattr(index, "tz", None) is None:
                index = index.tz_localize('UTC')
            else:
                index = index.tz_convert('UTC')
            index = index.tz_convert(OUTPUT_TIMEZONE)
            bars.index = index.tz_localize(None)

            # ê¸°ë³¸ ì»¬ëŸ¼ ì •ë¦¬ (Open, High, Low, Close, Volume)
            bars = bars[['open', 'high', 'low', 'close', 'volume']]
            bars.columns = ['Open', 'High', 'Low', 'Close', 'Volume']

            df = bars.sort_index().copy()

            # --- ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€ ---
            df['MA20'] = df['Close'].rolling(window=20).mean()
            df['RSI'] = calculate_rsi(df['Close'])
            df['MACD'], df['MACD_Signal'], _ = calculate_macd(df['Close'])
            df['ATR'] = calculate_atr(df)
            df['VWAP'] = calculate_vwap(df)

            # --- ê±°ì‹œì§€í‘œ ê²°í•© (ì¼ë´‰ì„ ì‹œê°„ì¶•ì— ë§ì¶° ì±„ìš°ê¸°) ---
            valid_macro_cols = []
            if available_macro_cols:
                macro_to_join = pd.DataFrame(index=df.index)
                for name in available_macro_cols:
                    series = macro_series.get(name)
                    if series is None:
                        continue
                    aligned = series.reindex(df.index, method='ffill')
                    if aligned.dropna().empty:
                        continue
                    aligned = aligned.ffill().bfill()
                    macro_to_join[name] = aligned
                    valid_macro_cols.append(name)

                if valid_macro_cols:
                    df = df.join(macro_to_join[valid_macro_cols], how='left')
                    df[valid_macro_cols] = df[valid_macro_cols].ffill().bfill()

            # --- ETF(QQQ, XLK) ì‹œì„¸ ê²°í•© ---
            etf_added_cols = []
            if etf_series:
                for symbol, series in etf_series.items():
                    aligned = series.reindex(df.index, method='ffill')
                    if aligned.dropna().empty:
                        continue
                    aligned = aligned.ffill().bfill()
                    df[symbol] = aligned
                    etf_added_cols.append(symbol)

            # ì‹œê°„ íŒŒìƒ ë³€ìˆ˜
            df['DayOfWeek'] = df.index.dayofweek
            df['Hour'] = df.index.hour

            # í•„ìˆ˜ ì»¬ëŸ¼ ê¸°ì¤€ìœ¼ë¡œ NaN ì œê±°
            required_columns = ['Close', 'Volume', 'MA20', 'RSI', 'MACD', 'MACD_Signal', 'ATR', 'VWAP']
            if valid_macro_cols:
                required_columns += valid_macro_cols
            if etf_added_cols:
                required_columns += etf_added_cols

            original_len = len(df)
            df.dropna(subset=required_columns, inplace=True)

            if len(df) == 0:
                print(f"âš ï¸ ë°ì´í„°ê°€ ëª¨ë‘ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. (ë³‘í•© ë¬¸ì œ ê°€ëŠ¥ì„±) ì›ë³¸: {original_len}í–‰")
                continue

            # ì¸ë±ìŠ¤ë¥¼ Datetime ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
            df.reset_index(inplace=True)
            df.rename(columns={'index': 'Datetime'}, inplace=True)

            # íŒŒì¼ ì €ì¥ (ê¸°ì¡´ ê²½ë¡œ + ìƒˆë¡œìš´ íŒŒì¼ëª… íŒ¨í„´)
            file_path = f"{SAVE_DIR}/{ticker}_hourly_alp_yf_dataset_v2.csv"
            temp_path = None
            try:
                fd, temp_path = tempfile.mkstemp(prefix=f"{ticker}_", suffix="_hourly_alp_yf_v2_tmp.csv", dir=SAVE_DIR)
                os.close(fd)
                df.to_csv(temp_path, index=False)
                os.replace(temp_path, file_path)
            except PermissionError:
                if temp_path and os.path.exists(temp_path):
                    os.remove(temp_path)
                print("âŒ ì—ëŸ¬: ëŒ€ìƒ CSVê°€ ì—´ë ¤ ìˆì–´ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ë‹«ê³  ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
                continue
            finally:
                if temp_path and os.path.exists(temp_path):
                    os.remove(temp_path)

            print(f"âœ… ì™„ë£Œ ({len(df)}í–‰)")
        except Exception as e:
            print(f"âŒ ì—ëŸ¬: {e}")

    print("\nğŸ ì§€ì •ëœ ê¸°ê°„ì˜ Alpaca+ê±°ì‹œ+ê¸°ìˆ +ETF ì‹œê°„ë³„ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ.")


if __name__ == "__main__":
    build_alpaca_yf_hourly_dataset()
